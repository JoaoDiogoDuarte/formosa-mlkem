#ifndef POLY_NTT_HH
#define POLY_NTT_HH

#include "params.jahh"
#include "poly_reduce.jahh"
#include "consts.jahh"

inline 
fn shuffle8(reg u256 a b) -> reg u256, reg u256
{
  reg u256 r0 r1; 
  r0 = #VPERM2I128(b,a,0x20);
  r1 = #VPERM2I128(b,a,0x31);
  return r0, r1;
}

inline 
fn shuffle4(reg u256 a b) -> reg u256, reg u256
{
  reg u256 r0 r1; 
  r0 = #VPUNPCKL_4u64(b,a);
  r1 = #VPUNPCKH_4u64(b,a);
  return r0, r1;
}

/*
inline 
fn shuffle2(reg u256 a b) -> reg u256, reg u256
{
  reg u256 r0 r1 t0 t1; 
  t0 = #VPSLL_u64(32,b);
  t1 = #VPSRL_u64(32,a);
  r0 = #VPBLENDD(t0,a);
  r1 = #VPBLENDD(t1,b,0xAA);
  return r0, r1;
}

inline 
fn shuffle1(reg u256 a b) -> reg u256, reg u256
{
  reg u256 r0 r1; 
  r0 = #VPUNPCKL_4u64(b,a);
  r1 = #VPUNPCKH_4u64(b,a);
  return r0, r1;
}
*/




inline
fn butterfly64x(reg u256 rl0 rl1 rl2 rl3 rh0 rh1 rh2 rh3 zl0 zl1 zh0 zh1 qx16) 
    -> reg u256, reg u256, reg u256, reg u256, reg u256, reg u256, reg u256, reg u256
{
  reg u256 t0 t1 t2 t3 t4 t5 t6 t7;

  t0 = #VPMULL_16u16(zl0, rh0);
  t1 = #VPMULH_16u16(zh0, rh0);
  t2 = #VPMULL_16u16(zl0, rh1);
  t3 = #VPMULH_16u16(zh0, rh1);
  t4 = #VPMULL_16u16(zl1, rh2);
  t5 = #VPMULH_16u16(zh1, rh2);
  t6 = #VPMULL_16u16(zl1, rh3);
  t7 = #VPMULH_16u16(zh1, rh3);

  t0 = #VPMULH_16u16(t0, qx16);
  t2 = #VPMULH_16u16(t2, qx16);
  t4 = #VPMULH_16u16(t4, qx16);
  t6 = #VPMULH_16u16(t6, qx16);

  //rh1 = #VPSUB_16u16(t3, rl1);
  rh1 = #VPSUB_16u16(rl1, t3);
  rl1 = #VPADD_16u16(t3, rl1);
  //rh0 = #VPSUB_16u16(t1, rl0);
  rh0 = #VPSUB_16u16(rl0, t1);
  rl0 = #VPADD_16u16(t1, rl0);
  //rh3 = #VPSUB_16u16(t7, rl3);
  rh3 = #VPSUB_16u16(rl3, t7);
  rl3 = #VPADD_16u16(t7, rl3);
  //rh2 = #VPSUB_16u16(t5, rl2);
  rh2 = #VPSUB_16u16(rl2, t5);
  rl2 = #VPADD_16u16(t5, rl2);

  rh0 = #VPADD_16u16(t0, rh0);
  //rl0 = #VPSUB_16u16(t0, rl0);
  rl0 = #VPSUB_16u16(rl0, t0);
  rh1 = #VPADD_16u16(t2, rh1);
  //rl1 = #VPSUB_16u16(t2, rl1);
  rl1 = #VPSUB_16u16(rl1, t2);
  rh2 = #VPADD_16u16(t4, rh2);
  //rl2 = #VPSUB_16u16(t4, rl2);
  rl2 = #VPSUB_16u16(rl2, t4);
  rh3 = #VPADD_16u16(t6, rh3);
  //rl3 = #VPSUB_16u16(t6, rl3);
  rl3 = #VPSUB_16u16(rl3, t6);

  return rl0, rl1, rl2, rl3, rh0, rh1, rh2, rh3;
}


inline fn level0(reg ptr u16[KYBER_N] rp) -> reg ptr u16[KYBER_N]
{
  reg u256 zeta0 zeta1 r0 r1 r2 r3 r4 r5 r6 r7 qx16;
  reg u32 t;
  reg u16 w;
  reg ptr u16[400] zetasp;
  reg ptr u16[16] qx16p;

  zetasp = jzetas_exp;
  qx16p = jqx16;

//  w = KYBER_Q;
  qx16 = jqx16[u256 0];

  zeta0 = #VPBROADCAST_8u32(zetasp[u32 0]);
  zeta1 = #VPBROADCAST_8u32(zetasp[u32 1]);

  r0 = rp.[u256 32*0];
  r1 = rp.[u256 32*1];
  r2 = rp.[u256 32*2];
  r3 = rp.[u256 32*3];
  r4 = rp.[u256 32*8];
  r5 = rp.[u256 32*9];
  r6 = rp.[u256 32*10];
  r7 = rp.[u256 32*11];

  r0, r1, r2, r3, r4, r5, r6, r7 = butterfly64x(r0, r1, r2, r3, r4, r5, r6, r7, zeta0, zeta0, zeta1, zeta1, qx16);

  rp.[u256 32*0] = r0;
  rp.[u256 32*1] = r1;
  rp.[u256 32*2] = r2;
  rp.[u256 32*3] = r3;
  rp.[u256 32*8] = r4;
  rp.[u256 32*9] = r5;
  rp.[u256 32*10] = r6;
  rp.[u256 32*11] = r7;

  r0 = rp.[u256 32*4];
  r1 = rp.[u256 32*5];
  r2 = rp.[u256 32*6];
  r3 = rp.[u256 32*7];
  r4 = rp.[u256 32*12];
  r5 = rp.[u256 32*13];
  r6 = rp.[u256 32*14];
  r7 = rp.[u256 32*15];

  r0, r1, r2, r3, r4, r5, r6, r7 = butterfly64x(r0, r1, r2, r3, r4, r5, r6, r7, zeta0, zeta0, zeta1, zeta1, qx16);

  rp.[u256 32*4] = r0;
  rp.[u256 32*5] = r1;
  rp.[u256 32*6] = r2;
  rp.[u256 32*7] = r3;
  rp.[u256 32*12] = r4;
  rp.[u256 32*13] = r5;
  rp.[u256 32*14] = r6;
  rp.[u256 32*15] = r7;

  return rp;
}

/*
inline fn level1t6half(reg ptr u16[KYBER_N/2] rp, reg u64 zetaoffset) -> reg ptr u16[KYBER_N/2]
{
  reg u256 zeta0 zeta1 zeta2 zeta3 r0 r1 r2 r3 r4 r5 r6 r7 qx16;
  reg u32 t;
  reg u16 w;
  reg ptr u16[400] zetasp;
  reg ptr u16[16] qx16p;

  zetasp = jzetas_exp;
  qx16p = jqx16;

  qx16 = jqx16[u256 0];

  // level 1
  zeta0 = #VPBROADCAST_8u32(zetasp.[u32 8]);
  zeta1 = #VPBROADCAST_8u32(zetasp.[u32 12]);

  r0 = rp.[u256 32*0];
  r1 = rp.[u256 32*1];
  r2 = rp.[u256 32*2];
  r3 = rp.[u256 32*3];
  r4 = rp.[u256 32*4];
  r5 = rp.[u256 32*5];
  r6 = rp.[u256 32*6];
  r7 = rp.[u256 32*7];
  
  r0, r1, r2, r3, r4, r5, r6, r7 = butterfly64x(r0, r1, r2, r3, r4, r5, r6, r7, zeta0, zeta0, zeta1, zeta1, qx16);

  // level 2
  zeta0 = zetasp.[u256 16];
  zeta1 = zetasp.[u256 48];

  r0, r4 = shuffle8(r0, r4);
  r1, r5 = shuffle8(r1, r5);
  r2, r6 = shuffle8(r2, r6);
  r3, r7 = shuffle8(r3, r7);
  
  r0, r4, r1, r5, r2, r6, r3, r7 = butterfly64x(r0, r4, r1, r5, r2, r6, r3, r7, zeta0, zeta0, zeta1, zeta1, qx16);

  // level 3
  zeta0 = zetasp.[u256 80];
  zeta1 = zetasp.[u256 112];

  r0, r2 = shuffle4(r0, r2);
  r4, r6 = shuffle4(r4, r6);
  r1, r3 = shuffle4(r1, r3);
  r5, r7 = shuffle4(r5, r7);
  
  r0, r2, r4, r6, r1, r3, r5, r7 = butterfly64x(r0, r2, r4, r6, r1, r3, r5, r7, zeta0, zeta0, zeta1, zeta1, qx16);

  // level 4
  zeta0 = zetasp.[u256 144];
  zeta1 = zetasp.[u256 176];

  r0, r1 = shuffle2(r0, r1);
  r2, r3 = shuffle2(r2, r3);
  r4, r5 = shuffle2(r4, r5);
  r6, r7 = shuffle2(r5, r7);
  
  r0, r1, r2, r3, r4, r5, r6, r7 = butterfly64x(r0, r1, r2, r3, r4, r5, r6, r7, zeta0, zeta0, zeta1, zeta1, qx16);

  // level 5
  zeta0 = zetasp.[u256 208];
  zeta1 = zetasp.[u256 240];

  r0, r4 = shuffle1(r0, r4);
  r1, r5 = shuffle1(r1, r5);
  r2, r6 = shuffle1(r2, r6);
  r3, r7 = shuffle1(r3, r7);
  
  r0, r4, r1, r5, r2, r6, r3, r7 = butterfly64x(r0, r4, r1, r5, r2, r6, r3, r7, zeta0, zeta0, zeta1, zeta1, qx16);

  // level 6
  zeta0 = zetasp.[u256 272];
  zeta1 = zetasp.[u256 336];
  zeta2 = zetasp.[u256 304];
  zeta3 = zetasp.[u256 368];

  r0, r4, r2, r6, r1, r5, r3, r7 = butterfly64x(r0, r4, r2, r6, r1, r5, r3, r7, zeta0, zeta1, zeta2, zeta3, qx16);

  r0 = redx16(r0, qx16);
  r4 = redx16(r4, qx16);
  r2 = redx16(r2, qx16);
  r6 = redx16(r6, qx16);
  r1 = redx16(r1, qx16);
  r5 = redx16(r5, qx16);
  r3 = redx16(r3, qx16);
  r7 = redx16(r7, qx16);

  rp.[u256 32*0] = r0;
  rp.[u256 32*1] = r4;
  rp.[u256 32*2] = r2;
  rp.[u256 32*3] = r6;
  rp.[u256 32*4] = r1;
  rp.[u256 32*5] = r5;
  rp.[u256 32*6] = r3;
  rp.[u256 32*7] = r7;

  return rp;
}
*/


fn poly_ntt(reg ptr u16[KYBER_N] rp) -> reg ptr u16[KYBER_N]
{
  reg u64 len;  
  reg u64 start;
  reg u64 j;
  reg u64 cmp;
  reg u64 offset;
  
  reg u16 zeta;
  reg u16 t;
  reg u16 s;
  reg u16 m;

  reg ptr u16[128] zetasp;
  reg u64 zetasctr;

  zetasp = jzetas;
  zetasctr = 0;
  len = 128;
  while (len >= 2)
  {
    start = 0;
    while (start < 256)
    {
      zetasctr += 1;
      zeta = zetasp[(int)zetasctr];
      j = start;
      cmp = start + len;
      while (j < cmp)
      {
        offset = j + len;
        t = rp[(int)offset];
        t = fqmul(t, zeta);
        s = rp[(int)j];
        m = s;
        m -= t;
        rp[(int)offset] = m;
        t += s;
        rp[(int)j] = t;
        j += 1;
      }
      start = j + len;
    }
    len >>= 1;
  }

  rp = poly_reduce(rp);

  return rp;
}

#endif
