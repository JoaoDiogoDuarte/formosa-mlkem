require "poly_compress.jinc"
require "poly_decompress.jinc"
require "poly_tobytes.jinc"
require "poly_frombytes.jinc"
require "poly_tomsg.jinc"
require "poly_frommsg.jinc"
require "poly_add2.jinc"
require "poly_sub.jinc"
require "poly_ntt.jinc"
require "poly_invntt.jinc"
require "poly_basemul.jinc"
require "poly_frommont.jinc"
require "poly_reduce.jinc"
require "poly_csubq.jinc"
require "poly_getnoise.jinc"
require "polyvec_tobytes.jinc"
require "polyvec_frombytes.jinc"
require "polyvec_compress.jinc"
require "polyvec_decompress.jinc"
require "polyvec_add2.jinc"
require "polyvec_pointwise_acc.jinc"
require "polyvec_ntt.jinc"
require "polyvec_invntt.jinc"
require "polyvec_csubq.jinc"
require "polyvec_reduce.jinc"
require "gen_matrix.jinc"
require "indcpa.jinc"
require "verify.jinc"

/* Exported functions only for benchmarking */
export fn gen_matrix_jazz(reg u64 ap, reg u64 seedp)
{
  stack u16[KYBER_K*KYBER_VECN] aa;
  stack u8[KYBER_SYMBYTES] seed;

  aa = __gen_matrix(seed, 1);
}

export fn poly_compress_jazz(reg u64 rp, reg u64 ap) 
{
  stack u16[KYBER_N] a;

  a = _poly_compress(rp, a);
}

export fn poly_decompress_jazz(reg u64 rp, reg u64 ap) 
{
  stack u16[KYBER_N] r;

  r = _poly_decompress(r, ap);
}

export fn poly_tomsg_jazz(reg u64 rp, reg u64 ap) 
{
  stack u16[KYBER_N] a;

  a = _poly_tomsg(rp, a);
}

export fn poly_frommsg_jazz(reg u64 rp, reg u64 ap) 
{
  stack u16[KYBER_N] r;

  r = poly_frommsg(r, ap);
}

export fn poly_ntt_jazz(reg u64 rp) 
{
  stack u16[KYBER_N] r;

  r = poly_ntt(r);
}

export fn poly_invntt_jazz(reg u64 rp) 
{
  stack u16[KYBER_N] r;

  r = poly_invntt(r);
}


export fn poly_getnoise_jazz(reg u64 rp, reg u64 seedp, reg u8 nonce) 
{
  stack u16[KYBER_N] r;
  stack u8[KYBER_SYMBYTES] seed;

  r = _poly_getnoise(r, seed, nonce);
}


export fn poly_getnoise_4x_jazz(reg u64 r0 r1 r2 r3, reg u64 seedp, reg u8 nonce) 
{
  stack u16[KYBER_N] r0 r1 r2 r3;
  stack u8[KYBER_SYMBYTES] seed;

  r0, r1, r2, r3 = _poly_getnoise_4x(r0, r1, r2, r3, seed, nonce);
}



export fn polyvec_decompress_jazz(reg u64 rp, reg u64 ap) 
{
  stack u16[KYBER_VECN] r;

  r = __polyvec_decompress(ap);
}


export fn polyvec_compress_jazz(reg u64 rp, reg u64 ap) 
{
  stack u16[KYBER_VECN] a;

  __polyvec_compress(rp, a);
}


export fn polyvec_pointwise_acc_jazz(reg u64 rp, reg u64 ap, reg u64 bp) 
{
  stack u16[KYBER_VECN] a;
  stack u16[KYBER_VECN] b;
  stack u16[KYBER_N] r;

  r = __polyvec_pointwise_acc(r, a, b);
}


export fn indcpa_keypair_jazz(reg u64 pkp, reg u64 skp, reg u64 randomnessp)
{
  __indcpa_keypair(pkp, skp, randomnessp);
}


export fn indcpa_enc_jazz(reg u64 ctp, reg u64 msgp, reg u64 pkp, reg u64 coinsp)
{
  stack u16[KYBER_VECN] pkpv sp ep bp;
  stack u16[KYBER_K*KYBER_VECN] aat;
  stack u16[KYBER_N] k poly epp v poly0 poly1 poly2;
  stack u8[KYBER_SYMBYTES] publicseed;
  stack u8[KYBER_SYMBYTES] noiseseed;
  reg u64 i j;
  reg u16 t;
  reg u8 c nonce;
  stack u64 sctp;

  sctp = ctp;

  i = 0;
  while (i < KYBER_SYMBYTES)
  {
    c = (u8)[coinsp+i];
    noiseseed[(int)i] = c;
    i += 1;
  }

  pkpv = __polyvec_frombytes(pkp);

  i = 0;
  pkp += KYBER_POLYVECBYTES;
  while (i < KYBER_SYMBYTES)
  {
    c = (u8)[pkp];
    publicseed[(int)i] = c;
    pkp += 1;
    i += 1;
  }

  k = poly_frommsg(k, msgp);

  aat = __gen_matrix(publicseed, 1);

  nonce = 0;
  sp[0:KYBER_N], sp[KYBER_N:KYBER_N], sp[2*KYBER_N:KYBER_N], ep[0:KYBER_N] = _poly_getnoise_4x(sp[0:KYBER_N], sp[KYBER_N:KYBER_N], sp[2*KYBER_N:KYBER_N], ep[0:KYBER_N], noiseseed, nonce);

  nonce = 4;
  ep[KYBER_N:KYBER_N], ep[2*KYBER_N:KYBER_N], epp, bp[0:KYBER_N] = _poly_getnoise_4x(ep[KYBER_N:KYBER_N], ep[2*KYBER_N:KYBER_N], epp, bp[0:KYBER_N], noiseseed, nonce);

  sp = __polyvec_ntt(sp);
    
  bp[0:KYBER_N] = __polyvec_pointwise_acc(bp[0:KYBER_N], aat[0:KYBER_VECN], sp);
  bp[KYBER_N:KYBER_N]= __polyvec_pointwise_acc(bp[KYBER_N:KYBER_N], aat[KYBER_VECN:KYBER_VECN], sp);
  bp[2*KYBER_N:KYBER_N] = __polyvec_pointwise_acc(bp[2*KYBER_N:KYBER_N], aat[2*KYBER_VECN:KYBER_VECN], sp);
  
  v = __polyvec_pointwise_acc(v, pkpv, sp);

  bp = __polyvec_invntt(bp);
  v = poly_invntt(v);

  bp = __polyvec_add2(bp, ep);
  v = _poly_add2(v, epp);
  v = _poly_add2(v, k);
  bp = __polyvec_reduce(bp);
  v  = poly_reduce(v);

  ctp = sctp;
  __polyvec_compress(ctp, bp);
  ctp += KYBER_POLYVECCOMPRESSEDBYTES;
  v = _poly_compress(ctp, v);
}


export fn indcpa_dec_jazz(reg u64 msgp, reg u64 ctp, reg u64 skp)
{
  stack u16[KYBER_N] t v mp;
  stack u16[KYBER_VECN] bp skpv;

  bp = __polyvec_decompress(ctp);
  ctp += KYBER_POLYVECCOMPRESSEDBYTES;
  v = _poly_decompress(v, ctp);

  skpv = __polyvec_frombytes(skp);
  
  bp = __polyvec_ntt(bp);
  t = __polyvec_pointwise_acc(t, skpv, bp);
  t = poly_invntt(t );

  mp = _poly_sub(mp, v, t);
  mp = poly_reduce(mp);
  
  mp = _poly_tomsg(msgp, mp);
}

export fn crypto_kem_keypair_jazz(reg u64 pkp, reg u64 skp, reg u64 randomnessp)
{
  stack u8[32] h_pk;
  stack u64 s_randomnessp s_skp s_pkp;
  reg u64 t64;
  inline int i;

  s_randomnessp = randomnessp;
  s_pkp = pkp;
  s_skp = skp;

  __indcpa_keypair(pkp, skp, randomnessp);

  randomnessp = s_randomnessp;
  randomnessp += KYBER_SYMBYTES;
  s_randomnessp = randomnessp;

  skp = s_skp;
  skp += KYBER_POLYVECBYTES;
  pkp = s_pkp;

  for i=0 to KYBER_INDCPA_PUBLICKEYBYTES/8
  {
    t64 = (u64)[pkp + 8*i];
    (u64)[skp] = t64;
    skp += 8;
  }

  s_skp = skp;
  pkp = s_pkp;
  t64 = KYBER_POLYVECBYTES + KYBER_SYMBYTES;
  h_pk = _isha3_256(h_pk, pkp, t64);
  skp = s_skp;

  for i=0 to 4
  {
    t64 = h_pk[u64 i];
    (u64)[skp] = t64;
    skp += 8;
  }
  
  randomnessp = s_randomnessp;

  for i=0 to KYBER_SYMBYTES/8
  {
    t64 = (u64)[randomnessp + 8*i];
    (u64)[skp] = t64;
    skp += 8;
  }
}


export fn crypto_kem_enc_jazz(reg u64 ctp, reg u64 shkp, reg u64 pkp, reg u64 randomnessp)
{
  stack u8[KYBER_SYMBYTES * 2] buf kr;
  stack u64 s_pkp s_ctp s_randomnessp s_shkp;
  reg u64 t64;

  s_pkp = pkp;
  s_ctp = ctp;
  s_shkp = shkp;
  
  t64 = KYBER_SYMBYTES;
  buf[0:KYBER_SYMBYTES] = _isha3_256(buf[0:KYBER_SYMBYTES], randomnessp, t64);

  s_randomnessp = randomnessp;
  pkp = s_pkp;

  t64 = KYBER_PUBLICKEYBYTES;
  buf[KYBER_SYMBYTES:KYBER_SYMBYTES] = _isha3_256(buf[KYBER_SYMBYTES:KYBER_SYMBYTES], pkp, t64);

  kr = _sha3_512_64(kr, buf);

  pkp = s_pkp;

  __indcpa_enc(s_ctp, buf[0:KYBER_SYMBYTES], pkp, kr[KYBER_SYMBYTES:KYBER_SYMBYTES]);

  ctp = s_ctp;
  t64 = KYBER_CT_LEN;
  kr[KYBER_SYMBYTES:KYBER_SYMBYTES] = _isha3_256(kr[KYBER_SYMBYTES:KYBER_SYMBYTES], ctp, t64);

  shkp = s_shkp;
  t64 = KYBER_SSBYTES;
  _shake256_64(shkp, t64, kr);
}


export fn crypto_kem_dec_jazz(reg u64 shkp, reg u64 ctp, reg u64 skp)
{
  stack u8[KYBER_CT_LEN] ctpc;
  stack u8[2*KYBER_SYMBYTES] kr buf;
  stack u64 s_skp s_ctp s_shkp;
  reg u64 pkp hp zp t64 cnd;
  inline int i;

  s_shkp = shkp;
  s_ctp = ctp;

  buf[0:KYBER_MSGBYTES] = __indcpa_dec(buf[0:KYBER_MSGBYTES], ctp, skp);

  hp = skp + 32;
  hp += 24 * KYBER_K * KYBER_N>>3;

  for i=0 to KYBER_SYMBYTES/8
  {
    t64 = (u64)[hp + 8*i];
    buf.[u64 KYBER_SYMBYTES + 8*i] = t64;
  }

  s_skp = skp;

  kr = _sha3_512_64(kr, buf);

  pkp = s_skp;
  pkp += 12 * KYBER_K * KYBER_N>>3;

  ctpc = __iindcpa_enc(ctpc, buf[0:KYBER_SYMBYTES], pkp, kr[KYBER_SYMBYTES:KYBER_SYMBYTES]);

  ctp = s_ctp;
  cnd = __verify(ctp, ctpc);

  zp = s_skp;
  zp += 64;
  zp += 24 * KYBER_K * KYBER_N>>3;
  kr[0:KYBER_SYMBYTES] = __cmov(kr[0:KYBER_SYMBYTES], zp, cnd);

  t64 = KYBER_CT_LEN;
  kr[KYBER_SYMBYTES:KYBER_SYMBYTES] = _isha3_256(kr[KYBER_SYMBYTES:KYBER_SYMBYTES], ctp, t64);

  shkp = s_shkp;
  t64 = KYBER_SSBYTES;
  _shake256_64(shkp, t64, kr);
}
